{"pages":[{"title":"tags","text":"","link":"/tags/index.html"},{"title":"Self Redemption","text":"I’ve done lots of thing make me regret and others’ heart break.Even now, I still cannot understand what I want in the future.Keep float in this fucking life.Keep exploring find what or who can make me culm.I deserve all the results I would have.","link":"/about/index.html"}],"posts":[{"title":"2019年5月(截止今天9号)面试的一些问题总结","text":"最近一直在面试, 因为也算是离开了一段时间吧. 所以面试效果感觉不尽人意对于一些问题进行了一下总结, 都是一些自我感觉没有答的很好的地方 数据库方面 谈一下数据库里索引的最左匹配原则 框架 springcloud zuul和nginx的区别 解决方案方面 redis 集群中带宽不够了怎么办 (感觉这个问题有点扯) nginx 性能出现瓶颈怎么办 对于nginx优化, 比如开启epoll和引入线程池 和并请求,增加tcp连接的使用效率 加快服务端的请求处理速度 有一个非常复杂的导出报表业务, 条件复杂, 且数据可能会发生改动. 怎么让相关人员能够快速的导出报表 核心思想: 预加载 使用数据库后, 很快性能出现了瓶颈, 并且服务器出现了假死现象, 怎么解决 假死和瓶颈方面很多. 应该从什么假死和什么瓶颈来着手","link":"/2019/05/09/2019年5月面试的一些问题总结/"},{"title":"How's my desktop looks like?","text":"It’s a hard work to collect everything I liked and need.But finally , mission completedNext step is add my PC join in.","link":"/2019/08/10/Hows-my-desktop-looks-like/"},{"title":"Hexo主题 icarus 添加异步刷新-pjax","text":"这两天更新Blog的时候,找到一个很好用的主题, 也就是现在这款: A simple, delicate, and modern theme for the static site generator Hexo. 也可通过右下角footer中的github图标进入. 但是原版的刷新模式是基于同步刷新, 无论点什么链接都会整屏刷新会导致浏览器整个页面闪一下, 感受很不好, 遂寻找异步刷新的解决方案. 经过一番搜索后, pjax进入了眼帘 GitHub: pushState + ajax = pjax 将引入代码添加到项目中正确到位置. 如果和我一样对前端比较生疏的人记得找准位置, 加载位置要在jquery 后面 &lt;script src=\"//cdn.bootcss.com/jquery.pjax/2.0.1/jquery.pjax.min.js\"&gt;&lt;/script&gt; 在 icarus 中, 我是将其放在了 scrips.ejs 中, 也就是刚好在 jquery 引入后 当然也可以通过npm $ npm install jquery-pjax 等其它方式引入 引入之后, 在找到对应的容器div, 即主体内容的加载容器对其进行全局唯一ID的定义在 icarus 中, 是 layout.ejs 将在包裹着 &lt;- body -&gt; 的div 声明一个Id 最后, 在 main.js 中初始化 pjax, 具体在哪声明, 根据不同主题的主函数定义位置 $(document).pjax('a', '#pjax-container', { fragment: '#pjax-container', timeout: 5000, cache: false}); 至此, 异步刷新界面达成","link":"/2019/08/11/Hexo主题添加异步刷新-pjax/"},{"title":"Java-送分题之Map","text":"Map的一些相关问题可以说是面试官最喜欢的问题了. 那么我们就系统性的说说这个问题 常用实现类 HashTable HashMap WeakHashMap LinkedHashMap ConcurrentHashMap TreeMap 特点及使用目的 HashTable 线程安全, 目前基本已经舍弃不使用 HashMap 线程不安全, 大量使用, 存储速度快, 查找速度快,常用于线程安全的线程中做中间变量 WeakHashMap 继承以上HashMap的所有优缺点, 多了一个特性: 其KV对象Entry,会在其Key中只有Map本身引用的时候进行删除 LinkedHashMap 基于HashMap进行数据存储实现, 并在每个元素中加入了链表属性来维持其元素的顺序性 ConcurrentHashMap 基于HashMap存储结构, 保证了线程安全 TreeMap 基于红黑树实现的Map, 并且有序 实现方式由于TreeMap的实现方式比较特殊, 所以我们先从Hash开始讲起 1. Map depend on hash首先我们要理解一下Map是什么, Map在这里的意思不是说地图, 指的是映射. 众所周知, Map是KV键值对, Map里面主要解决的就是如何将K正确的指向V在我们的日常操作中的数据都是杂乱无章的, 甚至是没有规则的, 那么通过一定的方式将无章法的, 无规则的东西变成和章法,在一定范围或者规则内, 且便于操作的目标或者值, 这个过程就叫hash 比如我们常说的对数字取模. 我们有无穷多个数, 但是通过对某个数字n取模, 我们就会得到固定范围的0~n-1的数字. 所以, 对于数据分布足够宽, 足够平均分布的时候, 我们利用Hash实现的Map会得到最高性能的查询. 如果有疑问, 往下面看:在所有数据结构中, 我们知道在已知下标的情况下, 数组的查询速度是最快的. 复杂度为O(1)那么先定个目标, 我们采用数组来实现KV Map 那么问题来了: 如何使得K能直接查找到V, 也就是如何通过Key来对应到其对应值的下标呢? 假设我们的Key都是整数, 那么我们此时,数组长度为7, 那么为了得到一个0~6范围内的正整数, 我们对key进行一个hash, 即: hash = k % 7那么此时我们通过hash值就可以得到其对应位置, 并将数值存入到对应的数组位置当中 到这一步, 我们基于Hash的Map已经形成雏形 但是又一个新的问题诞生了:此时如果再来一个新元素K8 V8 如何插入?此处我们默认K8的值等于7. 那么按照我们之前的hash规则, 则会得到hash=0, 但是下标为0的位置已经有元素V0 的存在, 此处产生了hash冲突, 即K不同,但是取得的hash值是相同的我们需要一个额外的方法来存储哈希冲突的问题,此处就引入一个数据结构链表, 将发生hash冲突的值和已经存在的值相关联问题又来了: 值是放进去了, 但是如果我取得时候, 也是通过hash值来获取值, 我怎么知道取哪个呢?所以为了解决这个问题, 存的时候, 我们不仅要存储Value, 还要将Key给存储进去, 那么当遇到有链表的值得时候. 就遍历链表, 拿Key值去进行equals比较. 保证拿出的值是正确的.到这一步. 基本上正确的存数据于取数据就没有问题了. 但是由此也因为hash冲突的问题诞生了另一个问题: 如果这样不停的塞值. 比如从0~100000, 这样每个链表就越来越长越来越长, 以至于当我们随机一个key取值得时候, 基本都是在遍历链表. 这样就已经让我们失去数组快速查找的优势了.我们需要一个解决方案, 来解决hash冲突, 避免这样长链表的诞生. 从这里我们就开始讲Java的解决方案首先, 想要hash数值足够宽. 那么对于前面的k % length这个公式, 我们势必就是要扩大分母, 也就是对数组进行扩容.但是何时扩容?Java引进了一个负载因子的概念DEFAULT_LOAD_FACTOR: static final float DEFAULT_LOAD_FACTOR = 0.75f; 当数组中存在元素个数的个数达到数组长度*0.75f的时候, 开始对数组进行扩容 但是若数组长度并没有达到负载因子的长度的时候, 发生了严重的hash冲突, 也势必会产生非常严重的哈希冲突导致遍历大链表的情况发生.于是针对于这种情况(JDK1.7 实现方式), 在JDK1.8中, 当链表元素达到8的时候, 则会将链表结构改成红黑树. 利用红黑树的自我平衡特点来加快元素的查找,避免大链表的产生 关于红黑树的特性, 可以通过 红黑树在线演示 来了解其特性 正常状态下HashMap结构图 那么每次扩容, 扩容多少呢. 在JDK1.8 中, 每次扩容的长度都固定是2的n次幂, 为什么选这个数呢? hash % $ 2^n $等价于 hash &amp; $ 2^n - 1$(与运算) 补充: 与运算,和或运算一起无限接近于CPU实际运算的一种运算方式.视为 0 为false 1为true.4 % 2 = 0; 等价于 4 &amp; 2-1即(二进制) 1000 &amp; 0001 = 0000运算过程:位数不足0补足, 对应位进行逻辑计算 所以, 利用这个特性, 加快运算, 从而选择了2的n次幂 但是由于HashMap并没有引入锁的机制, 所以是线程不安全的, 尤其发生在resize()也就是数组扩容的时候 To Be Continue …. 2019年5月21日更新: resize()会出现什么问题呢? 首先我们来理清一下resize()做了哪些事情. 首先创建一个新的table[], 长度为 $2^n$.然后遍历原有table[]上的元素, 并对其进行rehash, 将原有元素重新附着到新的table上. exp 现我们有一个原始长度为2,且有数据存在的hashmap. 并且有两个线程A与B欲对其进行操作","link":"/2019/05/17/JAVA-送分题之Map/"},{"title":"MSI IG止步4强","text":"很遗憾IG止步了四强.但是同时也暴露出了诸多的问题无论是IG的野辅问题, 还是整体的BP, 最恐怖的还是揭露出了整整6年的时间, 国内的观众嘴脸还是那么丑恶 当初RNG输在了S8 八强, 开始各种梗; 现在IG倒在了4强, 依然还是那些梗, 只是主角变成了IG.说实话, 这几把比赛, 亦或者是整个这次MSI比赛 Ning的问题真的很大, 各种迷之操作, 这几局梦游的盲僧. 没有带好节奏的雷克赛都间接或者直接的一步步导致了比赛的走向. 辅助Baolan也是, 尤其是最后一把上路那波很有机会的反追, 直接单人开车到对面人群里. 没有硬控, 没有任何反打手段的塔姆直接被秒. 并且还有很多次都是因为打野和辅助的梦游被开团导致的团战. 从心里上来说真的不想IG输的, 因为IG只要一输, 国内LOL圈子就要热闹了. \b比赛还没完全结束就已经开始了各种刷屏嘲讽+玩梗. 各大论坛估计也要开始撕逼了. 希望IG每个人都能调整心态吧. 任何队伍都要经历这些的, SKT王朝的诞生都经历过一年S赛都进不去. 不要求建立王朝, 只想都问心无愧吧 期待再一次捧杯","link":"/2019/05/17/MSI-IG止步4强/"},{"title":"Java 线程池标准 ThreadPoolExecutor","text":"面试的时候问了我线程池的问题. 比如说用的哪个类, 里面的参数是怎样的. ThreadPoolExecutor pool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, BlockingQueue) corePoolSize: 核心池大小, 也就是核心线程数 线程池刚开始启动的时候, 默认为0, 如果当前工作线程数少于该值, 则创建新线程 BlockingQueue: 工作队列 若在添加新任务的时候, 线程池worker线程已经达到了corePoolSize的值,则将新任务放入workQueue当中等待 maximumPoolSize: 最大池大小, 也就是最大线程数 若BlockingQueue被沾满, 则判断该值申请新的线程开始消费workQueue中的任务, 新创线程不超过该值 keepAliveTime: 线程存活时间 如果我\bmaximumPoolSize - corePoolSize &gt; 0 的线程中有闲置线程, 则线程在该时间后进行销毁 timeUnit: 存活时间的单位 这里还有另外一个参数: handler 我们来看看jdk8中关于Execute()方法的注释 * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */如果当前运行线程数少于corePoolSize数目, 那么就会尝试创建一个新线程来执行任务这里的计算使用了Atom类来保证其运行在状态和count的原子性 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } 如果不能在在队列中安排task, 则会尝试新增加一个线程来处理新任务. 而如果创建失败, 则会拒绝新任务. 整体而言线程的工作做流程分为以下步骤: 添加新任务 线程核心数没有达到指定数目, 创建新线程 达到核心线程数, 安排进Queue中 Queue中线程数满, 且核心线程数没有空余, 创建新线程来对Queue进行处理, 以FIFO原则处理 若Queue满, 核心线程数满, 最大线程数也满, 如果此时定义了handler 则会以handler中的方法来处理新任务. 否则直接拒绝新任务的加入","link":"/2019/05/10/Java-线程池标准-ThreadPoolExecutor/"},{"title":"Mac 常用软件介绍","text":"无聊来写写我经常用的一些 Mac 软件,其中包括一些通用的生活类软件和一些开发需要的软件 首当其冲的就是社交软件, 各大厂商对于 Mac 的支持已经非常源生了. 例如微信, QQ 等哪怕一些小众的软件比如 YY 都有了比较好的支持, 所以有什么需要的软件直接去搜 Mac 版即可 Alfred首先要推荐的就是这款搜索神器 Alfre 对于一般用户或者中度用户来说免费版已经能够获得非常好的体验了 下载地址 Alfred 4 for Mac 对于 Alfred 的重点推荐在于 强大的索引, 即高效的快速的搜索本地文件能力, 只要你依稀记着某个文件的关键字, 就可以获得电脑上的一切结果. Customized Query. 设置好之后, 搜索的步骤再也不是, 打开浏览器 - 输入网址 - 选中输入框 - 输入内容了 你只需要输入你设定的关键字 即可输入搜索内容, alfred会自行打开浏览器并去目标地址进行搜索,当然, 这也少不了前期设置 再者就是对于系统的高度契合,无论是打开 app, 还是运行脚本亦或者是进行快捷计算. 当你熟练之后,一切都是那么的容易. IINA多媒体设备,当然少不了多媒体软件的支持, 作为目前 Mac 平台上最好用的播放软件, 不仅大小不超过 100G 更是从 UI 到功能, 都透露着为 Mac 打造的气息, 源生支持 PIP:画中画模式, 并且占用资源非常少. 下载地址 IINA - The modern media player for MacOS iStat Menu 这是一款全局监控软件, 可以监控包括内存,CPU,硬盘读写, 网络传输, 传感器等绝大部分硬件的运行状态与温度, 并且本身占有资源很小, 不会像 Mac 本身自带的 Monitor 一样打开会高度占用 CPU 资源 下载地址 An advanced Mac system monitor to your menubar 但是这个软件的完全版本是属于收费的. 请看左边(利益无关) Handshaker曾经, 我为在 Mac 上如何传输 Android 手机文件以及管理操碎了心, 直到我看到了一家我并不喜欢的公司出的产品, 就是介绍的 Handshaker. 综合体验上来说可以说是 Mac 上使用最省心的文件管理以及传输软件了. 对于这家公司. 不得不说,只要不是正业的产品线, 做的都挺好的 下载地址 锤子软件 - Handshaker Shadowsocks 这是一款神秘的软件, 功能就不说了, 不知道哪里下载 请上 Github Kantu （看图） Preview 的痛点大家都知道， 一个文件夹几十几百甚至更多的图片， 需要全选才能一一全尺寸查看. 这个是腾讯出品的一款图片查看软件，非常轻量级，在查看图片方面， 可以完全替代苹果的 Preview. 弥补了这个缺点 看图 - 轻松找照片 截图 这个也是腾讯出品的一款截图软件. 虽然 mac 自带的截图工具本身现在工具已经很强大了, 唯独对与常用的截图标注不是很友好. 而这款则完美的补足了这个功能. 缺点是可能会有快捷键冲突. 我将其快捷键分别改为 CMD + Shift + 1 和 2 分别对应着截图和录制 刚好再往后面的 345 就是苹果源生的截图快捷键 Jietu - 轻松便捷爱截图 Another Redis Desktop Manager目前用过的体验最好的 Redis GUI 管理界面, 开源免费, 就是和 Redis Desktop Manager 对着干的 下载地址Another Redis Desktop Manager 不过建议下载之后, 改下名字, 名字真的太长了","link":"/2019/08/10/Mac-常用软件介绍/"},{"title":"Mayday Forever","text":"Some live show link 干杯 后来的我们 feat 张惠妹 Flower of Mayday 倔强 - 鸟巢","link":"/2019/08/17/Mayday-Forever/"},{"title":"Mysql5.7+ 关于Json的处理 - 牢骚向","text":"最近在对数据库处理的时候, 遇到关于 Json 类型. 从 Sql 上来看, json 相关函数的加入对与现有的很多数据结构都是非常友好的其中用的比较多的函数包裹 JSON_SEARCH()JSON_EXTRACT() JSON_SEARCH 函数用于检索某列下的某个特定 key 值的位置信息.但是不能获得具体的对象JSON_EXTRACT 函数根据具体的 json 索引可以获取整个 json 对象, 例如 JsonArray 中的某个元素 但是两者联合使用的效果, 暂时没有实验出满意的结果 但是, 目前主流框架, 以及哪怕 jdbc 对于 json 的支持并不是很友好. 拿最主流的 Mybatis 与 Hibernate 来举例子: Mybatis要在 Mybatis 实现对 Json 的解析, 需要继承 Mybatis 的 TypeHandler 接口 public class MyHander&lt;T&gt; extends BaseTypeHandler&lt;T&gt;{ public MyHandler(Class&lt;T&gt; clazz){ ... } @Override public void setNonNullParameter(PreparedStatement ps, int i, T parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, this.toJson(parameter)); } @Override public T getNullableResult(ResultSet rs, String columnName) throws SQLException { return this.toObject(rs.getString(columnName), clazz); } @Override public T getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return this.toObject(rs.getString(columnIndex), clazz); } @Override public T getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return this.toObject(cs.getString(columnIndex), clazz); } private String toJson(T object) { try { return mapper.writeValueAsString(object); } catch (Exception e) { throw new RuntimeException(e); } } private T toObject(String content, Class&lt;?&gt; clazz) { if (content != null &amp;&amp; !content.isEmpty()) { try { return (T) mapper.readValue(content, clazz); } catch (Exception e) { throw new RuntimeException(e); } } else { return null; } } static { mapper.configure(Feature.WRITE_NULL_MAP_VALUES, false); mapper.setSerializationInclusion(Inclusion.NON_NULL); } ...} 实现之后还需要在 Mapper 中像注解或者 xml 配置文件中, 对相对应的字段进行类型描述. 总之就是步骤很麻烦的实现 Hibernate - dslquery目前利用 hibernate 也是基于 dslquery 实现的一套框架, 不考虑性能上来说, 对于 json 的查询还是很方便的, 因为只需要 注解声明是 @type(json)之后, 就可以直接存储. 但是确不支持单个的读取. 也就是说, 我只能通过写源生 sql 来查明我所需要数据的列, 然后再把整条列都查出来, 在对其进行一个筛选. 这一点在业务规范和小数据量的时候, 是没有问题的. 至少在代码书写上, 算是最省心的一种了 @Query(value = \"select apply_code from credit_application_status where to_be_processed is not null and to_be_processed -&gt; '$[*].handler' like concat('%', :handler, '%') or to_be_processed -&gt; '$[*].position' like concat('%', :position, '%')\", nativeQuery = true) List&lt;String&gt; toBeProcessedTaskId(@Param(value = \"handler\") String username, @Param(value = \"position\") String position); 但是目前, 除了自己实现以外, 没有其它更好的方法来实现对于 json 的高效且省心的操作. 有时候, 还不如直接存入 json 字符串操作来的方便. json 数据类型需谨慎使用","link":"/2019/08/14/Mysql5-7关于Json的处理/"},{"title":"Netty 再回首","text":"之前的工作上用过netty, 但是感觉理解上还是不够深刻, 便再次看了一下netty 模型和源码. 发现自己以前还是too naive Netty 到底快在哪Netty 为什么快Netty 与Tomcat等web容器的区别 Netty的模型以前第一次看netty的模型的时候, 以为自己看懂了. 其实并不然. 每次讨论到Netty模型的时候不可避免的会谈到IO模型的演变. 什么是I/O I/O : Output 和 Input. 任何计算机与存储介质或者计算机外界进行数据交换的行为都可以称之为IO操作. 例如文件读取, 网络请求等等. 一切的IO操作都是通过操作系统底层函数来实现的 若要了解其底层原理, 需要了解计算机系统 Java早期版本中,通过流的概念实现了 磁盘操作: File 字节操作: InputStream 和 OutputStream 字符操作: Reader 和 Writer 网络操作: Socket 流的概念很好理解: 将数据的传输想象成一条河流注入湖泊, 而湖泊就是目标对象 I/O模式 BIO(Blocking I/O) BIO是最早的I/O操作模型, 每一次I/O操作的时候, 例如写入一个文件: CPU将换从中的数据写入到磁盘需要等到写入完毕, 才会去执行下一个工作. AIO(Asynchronous I/O) NIO(Non-blocking I/O)","link":"/2019/05/10/Netty-再回首/"},{"title":"再见了,The Big Bang","text":"Thanks words in Nobel Prize by Dr. Sheldon Lee Cooper: Thank you Dr. Fellower.I have a very long and somewhat self-centered speech here.But I’d like to set it aside.Because this honor doesn’t just belong to me. I wouldn’t be up here if it weren’t for some very important people in my life.Beginning with my mother, father, meemaw, brother and sister.And my other family who I’m so happy to have here with us.I was under a misapprehension that my accomplishments were mine alone.Nothing to be further from the truth.I have ben encouraged, sustained, inspired and tolerated not only by my wife, but by the greatest group of friends anyone ever had.I’d like to ask them to stand.Dr. Rajesh Koothrappali.Dr. Bernadeette Rostenkowsi Wolowitz.Astronaut Howard Wolowitz.And my two dearest friends in the world,Penny HofstadterandDr. Leonard Hofstadter.I was there the moment Leonard and Penny met.He said to me that their babies would smart and beautiful.And now that they’re expecting, I have no doubt that that will be the case. Howard, Bernadette,Raj, Penny, Leonard,I apologize if I haven’t been the friend you deserve.But I want you to know in my way, I love you all. And I love you.Thank you. 2007年到2019年, 12年时间. 没有TBB一直陪伴着.曾经的, 过去的, 都开始要离去了.钢铁侠老了, 谢耳朵老了. 再见了.","link":"/2019/05/18/再见了-The-Big-Bang/"},{"title":"Nginx 高负载优化(转述自知乎, 笔记)","text":"出处: 知乎原文-Nginx百万优化此处为笔记向 1. 方法论 保持并发了连接数, 做到内存有效应用 高并发的同时保持高吞吐量 高并发问题分解 优化从三个方面优化. 应用, 框架, 内核 2. 硬件 3. 软件 4. 请求Nginx 模块结构 4.1 请求到来一个请求到来的时候,操作系统内核中有一个队列, 系统进程会对其进行调用. 由于有很多工作进程, 谁去调用是个问题. 负载均衡策略 现在有一个时间模块, 调用了epoll wait接口, accept建立好一个新的连接, 这时会分配到连接内存池, 这个内存池会在连接刚创建的时候分配, 而当连接关闭的时候进行释放 连接进入之后, 接下来就来到了Nginx模块, 这时候会加一个定时器, 60s, 建立好连接后60s没有收到客户端的信息就自动关闭; 如果60s过来之后就去分配内存, 读缓冲区. 操作系统内核收到请求后, 但是用于应用程序是处理不聊的, 因为现在还只是存在內核态内存, 没有读取到用户态内存. 所以这时候要内存分配, 从连接内存池这里分配. 大概1K内存 4.2 接受请求当收到请求之后, 接受url和header, 分配请求内存池, 这时候 request pool size 是4K.这个和刚才有差不多8倍差距: 当请求特别长时, 就会分配更大的, 刚刚1K不够用了, 不会一次性分配32K, 而是一次性分配8K, 如果8K以后还是不能解析到刚才的标识符, 就会分配第二个8K. 之前收到的所有东西都不会释放, 只是放一个指针, 放到url或者指到协议, 标识它有多长即可. 接下来解决header, 这个流程一模一样的没有什么区别，这时候还会有一个不够用的情况，当我接收完所有的header以后，会把刚刚的定时器给移除，移除后接下来做11个阶段的处理，也就是说刚刚所有的外部服务器都是通过很多的模块串成在一起处理一个请求的。 上图有个疑问: 11个阶段的http请求处理 刚刚读完header需要处理, 所以这时候第一阶段是post-read. 接下来会有rewrite, 还有access和preaccess 5. 应用层优化5.1 协议做应用层的优化先看协议层有什么可以优化的, 比如说编码方式, header每次都会去传用Nginx的架构,以至于浪费了很多的流量, 我们可以改善http2, 有很多这样的协议会大幅度提升它的性能 而如果你改善HTTP2, 则会带来其他问题, 比如http2必须走这条路. 这条路线又是一个很大的话题, 它涉及到安全性和性能, 是互相冲突的东西 5.2 压缩我们希望”商”越大越好, 压缩这里会有一个重点提出来的: 动态和静态. 比如我们用了拷贝, 比如说从磁盘中直接由内核来发给网卡, 但一旦压缩的话, 就不得不先把文件读到nginx, 交给后面的极内核去做一下处理. keepalive长连接也是一样的, 涉及到很多东西, 简单来看也是复用连接. 因为连接有一个慢启动的过程, 一开始他的窗口是比较小, 一次可能只传送很小的1K, 但后面可能会传送几十K, 所以你每次新建连接它都会重新开始. 非常慢.这里还涉及到一个问题, 因为nginx内核默认打开了一个连接空闲的时候, 长连接产生的作用也会下降. 5.3 提高内存使用率CPU通过缓存区来取出储存上东西的时候, 是一批一批取得, 每一批目前是64bytes, 所以默认的是8K, 如果你配了32, 会给你上升到64, 如果配了65 会上升到128, 因此它是一个一个序列化重组的, 所以了解这个东西以后再配的时候就不会再犯问题,. 5.4 限速限流到底在限什么? 最主要限在Nginx向客户端发送响应的速度. 5.5 Worker间负载均衡 5.6 超时5.7 缓存5.8 减少磁盘IO优化读取，Sendfile零拷贝、内存盘、SSD盘。减少写入，AIO，磁盘是远大于内存的，当它把你内存消化完的时候还会退化成一个调用。像thread pool只用读文件，当退化成这种模式变多线程可以防止它的主进程被阻塞住，这时候官方的博客上说是有9倍的性能提升。 6. 系统优化","link":"/2019/05/19/Nginx-高负载优化/"},{"title":"关于面试中系统设计","text":"很多情况下面试会遇到关于系统设计问题. 需要注意一下几点: 切勿立即深入设计或者过度设计 在条件不明的情况下, 不要立马开始设计, 与面试官详细了解业务需求等等 切勿立马提出框架等具体应用层 最好有过真实的设计","link":"/2019/05/23/关于面试中系统设计/"},{"title":"就这样吧,够了","text":"","link":"/2019/06/19/就这样吧-够了/"},{"title":"秒杀与拼团系统架构设计","text":"从业务上来看, 这两个系统有什么共同的特性呢? 瞬时性 用户了解活动时间后会在时间点周围记性大量的网络请求 用户数量限制 并不是参与有将, 永远都只有固定的, 少量的用户可以获得最终的商品 产品数量限制 获得的商品是有数量限制的 那么可能在活动开始的一瞬间,原本的QPS或者TPS 相对于普通时间段来说会以一个指数型增长.那么如何提高系统的抗压能力以及保证业务的正确性成为系统设计的根本. 我们首先来分析, 我们要解决什么问题. 假设现有一个秒杀活动吸引了20000个用户来参加, 那么最高并发理论值就是20000.对于原有系统来说, 这个瞬时并发会击垮原有的服务, 导致所有业务瘫痪. 对系统和用户的留存都是致命的. 维护原有业务 用户会在活动开始前对网站或者特定页面会有突然性的高刷新的频率. 而如果按照一般的设计, 会对应用服务, 数据库访问以及相对应页面资源服务造成极大的压力 应用数据库负载 如果一个用户页面大小是100K那么需要的网络和服务器贷款就是 2G= 100K * 20000. 带宽是很贵的. 没有任何一家公司会购买高于平均使用量的带宽 带宽压力 很多情况下, 一个稍微有点计算机基础的人都可以通过html挖出很多网站的元素. 如果秒杀地址是暴露的, 那么很容易给这部分用户写成脚本来恶意竞争或者对服务器进行攻击. 秒杀URL和下单业务流程 针对以上问题. 我们逐步来分析: 秒杀系统独立部署由于秒杀服务于常规业务的流量有很大的不同, 为了维护原有的系统架构并且保护一半业务系统, 我们应当将秒杀业务独立的分离出. 并对其进行伸缩性部署和负载均衡.如果需要, 可以对其使用独立域名. 这样即使秒杀系统奔溃了. 也可以让用户找得到投诉的地方 秒杀页面优化如果是网页,并且原有的页面是通过动态生成的. 那么这部分的页面, 我们需要对其进行静态化, 并且将页面提前写入缓存当中. 并且对其中的一些数据进行写死或者直接写在缓存中, 减少并发时对于数据库的负载. 并对静态资源进行CDN部署, 保证用户访问速率 活动带宽活动之前不要忘记提前租借带宽哦. 不然因为带宽不够影响业务就尴尬了 动态URL为了避免用户直接下单. URL应该是动态的. 每次产生生成订单的行为之后, 应该由服务器生成一个带随机数的URL来给用户指向订单支付页面. 整个系统大致如下 其中还有很多针对不同场景或者平台的一些优化. 待续","link":"/2019/05/23/秒杀与拼团系统架构设计/"},{"title":"笔记: MysqlInnoDB 缓冲池详解","text":"InnoDB存储是基于磁盘存储的, 并且将其中记录按页的方式进行管理(InnoDB中数据最小单位是页)为了弥补CPU与磁盘之间速度的鸿沟, 引入了缓冲池来提高数据写入的性能 缓冲池是一个什么样的存在 当读取数据的时候, 首先将磁盘的读取到的数据页存储到缓冲池中. 这个过程叫”Fix”到缓冲池当下一次再读取该页的时候, 判断是否在缓冲池中, 若缓存命中, 则直接读取该页, 否则读取磁盘 当对数据库中的页进行修改的时候, 首先修改在缓冲池的页. 然后再以一定的频率刷新到磁盘上.此处频率不是事实, 而是通过redo-log的checkpoint机制来进行控制 所以缓冲池的大小影响着数据库的整体性能. 在32位系统下, 最多为3G, 但是可以通过打开操作系统的PAE选项来获得32位操作系统下最大64G的内存支持. 推荐64位, 最多512G内存 设置缓存池大小: innodb_buffer_pool_size=16105127360 缓冲池的数据在缓冲池中, 保存着例如: 索引页, 数据页, undo页, 插入缓冲, 自适应哈希索引, 锁信息, 数据字典信息等索引页和数据页占了其中很大一部分 缓冲池可配备多个实例: innodb_buffer_pool_instances=1 默认为1. 设置大于一便可得到多个缓冲区 那么既然作为缓存, 那么肯定牵涉到热点数据以及LRU等一系列问题. 如何判断数据是否热点, 缓冲池如何管理数据? 1. LRU List, Free List 和 Flush List1.1 LRU List和传统缓存一样, InnoDB也是通过LRU算法来对数据进行管理.在LRU List中, 使用次数多的数据再列表的前端, 反之则在末端. 当缓冲池不能存放新的数据的时候, 首先释放末尾页 在InnoDB中, 页的默认大小为16K 当缓冲池往里插入新的数据的时候, 并不是直接将数据放入到首或尾, 在这里InnoDB引入了一个midpoint的概念. innodb_old_block_pct=37 (%)在InnoDB中, 将midpoint之后的数据成为old, 之前称之为new列表, 在new列表中的数被成为最热点数据 当插入新的数据的时候, 会默认将数据插入到列表37%的位置. 也就是差不多3/8的位置.为什么不讲读取到的页直接放入到LRU列表首位呢?问题在于某些SQL操作做, 可能会使缓冲池的页被刷新出.比如一个查询操作中, 某些页仅仅只在这次查询中需要被用到. 而如果将查询到页放到首位, 则很有可能将真正热点的数据给挤出热点数据范围. 而当下一次需要读取热点页的时候, 又要重新从磁盘获取.采用midpoint仅仅只是从概率上降低了这种概率, 而不是完全规避. 在InnoDB中, 还同时引入了另一个参数来管理里LRU列表 innodb_old_blocs_time=1000 (second) 用于表示页读取到mid位置后需要等待多久才会被加入LRU列表的热端数据. 也就是说 当一个数据被插入之后, 需要存活多久才能去最热点数据端. 从而尽可能的使热点数据不被刷出LRU列表当页从LRU 列表的old部分加入到new部分时, 这个操作称为 page made young, 而如果因为innodb_old_blocks_time的配置导致页没有从old-&gt;new, 这个部分操作称为page not made young. 可以通过 SHOW ENGINE INNODB STATUS 来进行观察 在InnoDB1.0.x版本开始支持压缩页的功能, 如我们先前所知, 默认页大小为16K 压缩到1K,2K,4K和8K而由于页的大小发生变化, LRU了列表也有了一些变化. 通过unzip_LRU来进行管理这些压缩页, 不同大小的页对应不同的unzip_LRU.而不到16K的页申请内存过程如下: 检查4KB的unzip_LRU列表, 检查是否有空闲页 若有, 直接使用 若无, 检查8KB的unzip_LRU列表 若能够得到空闲页, 将页分成2个4KB页, 存放到4KB的unzip_LRU列表; 若无法申请到空闲页, 则直接向LRU列表申请一个16KB的页, 将页分为1个8KB和2个4KB, 分别存储到对应的unzip_LRU列表中 1.2 Free List当Mysql启动的时候, LRU List 是没有任何数据的,LRU List 是管理已经读取的页. 这时候所有的页是存在于Free List中. 当下需要从缓冲池中分也是, 首先从FreeList中查找是否有空闲页. , 若有则将该页从Free List中删除, 放入到LRU列表中. 否则从LRU old部分淘汰末尾页, 将内存空间分配给新页 1.3 Flush List如我们开头所讲的. 任何SQL操作都是优先在缓冲区或者将数据读到缓冲区进行页的更改, LRU列表中的页被修改之后, 称为脏页(Dirty Page)这时候数据库会通过CHECKPOINT机制来将脏页刷回磁盘, 而Flush List中则存储着所有的脏页数据. * 脏页同时存在于LRU List 和 Flush List当中. * 2. redo-log 缓冲redo-log 又叫重做日志. InnoDB现将重做日志缓存在缓冲池中, 再将其内容刷到磁盘日志文件. innodb_log_buffer_size一般大小8M即可.因为下一秒这些数据就刷新到日志文件 日志文件更新条件: 主线程定时每秒将redo刷到日志文件 事务提交时 当redo-log 缓冲池剩余空间小于1/2时 3. additional memory pool这些是 缓冲池存储例如 LRU 锁 等待等信息的时候 申请内存空间的地方. 4. CheckPoint之前说到了几个地方都是基于CheckPoint来进行操作. 其实CheckPoint就和游戏中的检查点一样.试想, 由于事务数据库都采用了Write Ahead Log 来保证ACID中的D(Durability)持久性.我们假设: 缓冲池可以缓存数据库中的所有数据 重做日志可以无限增大 缓存池既然可以存入所有数据, 那么就可以不用写入磁盘. 那么每当数据库进行事务提交的时候, redo日志页随之更新日积月累, 这个日志将会愈加庞大. 当数据库真正需要恢复的时候, 数据库根据redo日志将数据恢复到缓冲池中, 这个代价是相当巨大的. 现实明显不可能如此. 那么就像保存游戏一样, 只要之前的数据已经确确实实的保存到磁盘中, 游戏进度进行保存之后, 后续出现的问题我们都从最后一次的checkpoint开始CheckPoint解决了一下问题: 缩短数据库的恢复时间 缓冲池不够用时, 将脏页刷新到磁盘. 重做日志不可用时, 刷新脏页 这里解释一下第三点, 什么是重做日志不可用?重做日志出现不可用的情况是事务数据库系统对于重做日志的设计都是循环使用的, 并不是让其无限增大的. 重做日志可以被重用的部分是指这些重做日志已经不再需要, 即数据库宕机时不需要这部分日志来来进行恢复. 因此这部分日志就可以被覆盖重用. 若此时重做日志还需要被使用, 那么必须强制产生CheckPoint, 将缓冲池的页至少刷新到当前重做日志的位置. 在InnoDB内部, CheckPoint有两种: Sharp CheckPoint Fuzzy CheckPoint Sharp CheckPoint 发生在数据库关闭时, 将所有的脏页都刷回磁盘, 这是默认工作Fuzzy CheckPoint 发生在InnoDB运行时, 只刷一部分脏页回磁盘, 否则每次都全部刷新I/O资源开销会非常巨大在这其中可能会发生以下几种Fuzzy CheckPoint: Master Thread FLUSH_LRU_LIST Async/Sync Flush Dirty Page too much Master Thread发生的CP 可以理解为一个定时任务, 固定的将一部分脏页刷回磁盘, 这是个异步操作FLUSH_LRU_LIST 是因为InnoDB保证LRU列表中需要有差不多100个空闲页使用. Page Cleaner线程会异步的检查LRU中是否存在足够的可用页而如果空间不够, 则进行FLUSH_LRU_LIST CheckPointAsync/Sync Flush 是指发生在redo日志不可用的情况下, 需要强制将一些页刷回磁盘.此时脏页是从脏页列表中获取的(Flush List). 写入重写的日志的记为redo_lsn而已经舒心回磁盘记为checkpoint_lsnDirty Page too much 则是脏页太多进行的强制刷新, 利用参数innodb_max_dirty_pages_pct进行控制 innodb_max_dirty_pages_pct=80 (%)","link":"/2019/05/22/笔记-Mysql缓存详解/"},{"title":"视频测试: B站视频","text":"","link":"/2019/05/18/视频测试-B站视频/"}],"tags":[{"name":"面试","slug":"面试","link":"/tags/面试/"},{"name":"Show","slug":"Show","link":"/tags/Show/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"送分题","slug":"送分题","link":"/tags/送分题/"},{"name":"LOL","slug":"LOL","link":"/tags/LOL/"},{"name":"MSI","slug":"MSI","link":"/tags/MSI/"},{"name":"IG","slug":"IG","link":"/tags/IG/"},{"name":"线程池","slug":"线程池","link":"/tags/线程池/"},{"name":"笔记","slug":"笔记","link":"/tags/笔记/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"怀念","slug":"怀念","link":"/tags/怀念/"},{"name":"Video","slug":"Video","link":"/tags/Video/"},{"name":"后端","slug":"后端","link":"/tags/后端/"},{"name":"高并发","slug":"高并发","link":"/tags/高并发/"},{"name":"系统设计","slug":"系统设计","link":"/tags/系统设计/"},{"name":"Bilibili","slug":"Bilibili","link":"/tags/Bilibili/"},{"name":"Mayday","slug":"Mayday","link":"/tags/Mayday/"},{"name":"五月天","slug":"五月天","link":"/tags/五月天/"}],"categories":[{"name":"Code","slug":"Code","link":"/categories/Code/"},{"name":"Posts","slug":"Posts","link":"/categories/Posts/"},{"name":"Coder","slug":"Coder","link":"/categories/Coder/"},{"name":"Game","slug":"Game","link":"/categories/Game/"},{"name":"Share","slug":"Share","link":"/categories/Share/"},{"name":"Back-End","slug":"Back-End","link":"/categories/Back-End/"},{"name":"Life","slug":"Life","link":"/categories/Life/"},{"name":"Notes","slug":"Notes","link":"/categories/Notes/"},{"name":"Bili-Bili","slug":"Bili-Bili","link":"/categories/Bili-Bili/"}]}